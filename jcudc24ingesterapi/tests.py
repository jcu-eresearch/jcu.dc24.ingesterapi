import datetime
from sqlalchemy.dialects.mysql.base import DOUBLE
import os
import unittest
from sqlalchemy.types import BOOLEAN
import sys
import tempfile

from jcudc24ingesterapi.models.dataset import Dataset
from jcudc24ingesterapi.models.locations import Location, Region
from jcudc24ingesterapi.schemas.data_types import FileDataType
from jcudc24ingesterapi.models.data_sources import PullDataSource, PushDataSource
from jcudc24ingesterapi.models.data_entry import DataEntry
from jcudc24ingesterapi.ingester_platform_api import IngesterPlatformAPI
from jcudc24ingesterapi.authentication import CredentialsAuthentication
from jcudc24ingesterapi.models.metadata import Metadata
from jcudc24ingesterapi.schemas.metadata_schemas import QualityMetadataSchema, SampleRateMetadataSchema, NoteMetadataSchema, QualityMetadataSchema, MetadataSchema
from jcudc24ingesterapi.models.sampling import RepeatSampling, PeriodicSampling, CustomSampling
from jcudc24ingesterapi.ingester_exceptions import UnsupportedSchemaError, InvalidObjectError, UnknownObjectError, AuthenticationError


class ProvisioningInterfaceTest(unittest.TestCase):
    """
    This test defines and checks that the Ingester API works the way the provisioning interface expects.
    """
    def setUp(self):
        self.auth = CredentialsAuthentication("casey", "password")
        self.ingester_platform = IngesterPlatformAPI("http://localhost:8080", self.auth)
        self.cleanup_files = []

    def test_api_usage(self):
#       User data that is created by filling out the provisioning interface workflow steps.
        #   General
        title = "Test project"
        data_manager = "A Person"
        project_lead = "Another Person"

        #   Metadata
        project_region = Region("Test Region", ((1, 1), (2, 2),(2,1), (1,1)))

        #   Methods & Datasets
        extended_file_schema = FileDataType()
        extended_file_schema.temperature = DOUBLE()    # TODO: This is probably wrong - I'm not sure how it is being done now

        loc1 = Location(10.0, 11.0, "Test Site", 100)
        loc2 = Location(11.0, 11.0, "Test Site", 100)
        loc3 = Location(12.0, 11.0, "Test Site", 100)


        dataset1 = Dataset(None, FileDataType(), extended_file_schema)
        dataset2 = Dataset(None, FileDataType(), PullDataSource("http://test.com", "file_handle"), None, "file://d:/processing_scripts/awsome_processing.py")
        dataset3 = Dataset(None, FileDataType(), PullDataSource("http://test.com", "file_handle"), CustomSampling("file://d:/sampling_scripts/awsome_sampling.py"), "file://d:/processing_scripts/awsome_processing.py")

        self.cleanup_files.push(dataset2.processing_script)
        self.cleanup_files.push(dataset3.sampling.script)
        self.cleanup_files.push(dataset3.processing_script)

#       Provisioning admin accepts the submitted project
        work = self.ingester_platform.createUnitOfWork()

        project_region_id = work.post(project_region)    # Save the region

        loc1.region = project_region_id                  # Set the datasets location to use the projects region
        loc1_id = work.post(loc1)                        # Save the location
        dataset1.location = loc1_id                            # Set the datasets location
        dataset1_id = work.post(dataset1)                # Save the dataset

        loc2.region = project_region_id
        loc2_id = work.post(loc2)
        dataset2.location = loc2_id
        dataset2_id = work.post(dataset2)

        loc3.region = project_region_id
        loc3_id = work.post(loc3)
        dataset3.location = loc3_id
        dataset3_id = work.post(dataset3)

        # TODO: Nigel - How would I know that it worked/failed?
        if work.commit():
            # TODO: Nigel - I can't see any way of getting the real id from the work
            project_region.id = work.getRealId(project_region_id)

            loc1.id = work.getRealId(loc1_id)
            dataset1.id = work.getRealId(dataset1_id)
            loc2.id = work.getRealId(loc2_id)
            dataset2.id = work.getRealId(dataset2_id)
            loc3.id = work.getRealId(loc3_id)
            dataset3.id = work.getRealId(dataset3_id)

        else:
            assert(True, "Project creation failed")

        # Region, location and dataset id's will be saved to the project within the provisioning system in some way


#       User searches for datasets

        # TODO: Nigel? - Define searching api
        found_dataset_id = dataset1.id                  # The dataset that has an extended file schema

#       User manually enters data
        data_entry = DataEntry(found_dataset_id, datetime.datetime.now().strftime("%Y-%m-%d %H:%M"))
        data_entry['temperature'] = 27.8                # Add the extended schema items
        data_entry['mime_type'] = "text/xml"
        data_entry['file_handle'] = "file://c:/test_file.txt"

        try:
            data_entry = self.ingester_platform.post(data_entry)
            assert(data_entry.id is None, "Data Entry failed")
        except:
            assert(True, "Data Entry failed")

#       User enters quality assurance metadata
        entered_metadata = Metadata(data_entry.data_entry_id, QualityMetadataSchema())
        entered_metadata.unit = "%"
        entered_metadata.description = "Percent error"
        entered_metadata.value = 0.98

        try:
            entered_metadata = self.ingester_platform.post(entered_metadata)
            assert(entered_metadata.metadata_id is None, "Metadata failed")
        except:
            assert(True, "Metadata failed")

#       User changes sampling rate
        sampling_rate_changed = Metadata(data_entry.data_entry_id, SampleRateMetadataSchema())
        sampling_rate_changed.change_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        sampling_rate_changed.sampling = CustomSampling("file://d:/sampling_scripts/awsome_sampling.py")

        try:
            sampling_rate_changed = self.ingester_platform.post(sampling_rate_changed)
            assert(sampling_rate_changed.metadata_id is None, "Sampling rate change failed")
        except:
            assert(True, "Sampling rate change failed")

#       User wants some random metadata specific to their project
        random_metadata_schema =  MetadataSchema()
        random_metadata_schema.random_field = DOUBLE()

        random_metadata = Metadata(data_entry.data_entry_id, random_metadata_schema)
        random_metadata.random_field = 1.5

        try:
            random_metadata = self.ingester_platform.post(random_metadata)
            assert(random_metadata.metadata_id is None, "random_metadata failed")
        except:
            assert(True, "random_metadata failed")

#       User changes the data source of the dataset
        new_data_source = PullDataSource("http://test.com/new_data", "file_handle")
        dataset1.data_source = new_data_source
        try:
            dataset1 = self.ingester_platform.post(dataset1)
        except:
            assert(True, "data_source change failed")

#       External, 3rd party searches for data
        # TODO: external 3rd parties should be able to use the api to get data without authentication
        # TODO: I'm not sure exactly how this should work, but the search api could be open access (need spam limitations or something?)

#       Project is disabled/finished
        # TODO: Nigel - Create the disable method
        try:
            work = self.ingester_platform.createUnitOfWork()
            work.disable(dataset1)
            work.disable(dataset2)
            work.disable(dataset3)
            if not work.commit():
                assert(True, "disable commit failed")
        except:
            assert(True, "disable failed")

#       Project is obsolete and data should be deleted
        try:
            work = self.ingester_platform.createUnitOfWork()
            work.delete(dataset1)
            work.delete(dataset2)
            work.delete(dataset3)
            if not work.commit():
                assert(True, "delete commit failed")
        except:
            assert(True, "delete failed")


    def tearDown(self):
        self.ingester_platform.reset()

        for file in self.cleanup_files:
            try:
                os.remove(file)
            except:
                print "failed to remove file: " + file




class TestIngesterModels(unittest.TestCase):
    def test_authentication(self):
        pass

    def test_ingester_exceptions(self):
        pass

#    def test_ingester_platform(self):
#        self.ingester_platform = IngesterPlatformAPI()
#        dataset = self.ingester_platform.post(self.auth, self.dataset)
#        self.assertTrue(dataset is set, "Failed to add dataset to ingester API")
#        self.assertTrue(dataset.dataset_id is set and dataset.dataset_id >= 0,
#            "Ingester API returned dataset with invalid dataset_id")
#        self.dataset = dataset
#
#        data_entry = self.ingester_platform.post(self.auth, self.data_entry)
#        self.assertTrue(data_entry is set, "Failed to add data_entry to ingester API")
#        self.assertTrue(data_entry.data_entry_id is set and data_entry.data_entry_id >= 0,
#            "Ingester API returned data_entry with invalid data_entry_id")
#        self.data_entry = data_entry
#
#        datasets = self.ingester_platform.get(self.auth, Dataset())    # Get all datasets
#        self.assertTrue(len(datasets) > 0, "Ingester API failed to insert dataset")
#        self.assertIn(self.dataset, datasets, "Ingester API didn't return the inserted dataset")
#
#        data_quality = Metadata(self.data_entry, QualityMetadataSchema(), {"description": "Sensor was moved", "value": 0})
#        stored_data_quality = self.ingester_platform.post(self.auth, data_quality)
#        self.assertEquals(data_quality, stored_data_quality)
#
#        sampling_rate = Metadata(self.dataset, SampleRateMetadataSchema(), {"sampling": PeriodicSampling()})
#
#        location_elevation_type = Metadata(self.location, NoteMetadataSchema(),
#                {"name": "Elevation type", "text": "Height above ground"})


    def test_ingester_scripts(self):
        pass


class TestIngesterService(unittest.TestCase):
    """This set of tests checks that the CRUD functionality works as expected
    """
    def setUp(self):
        self.auth = CredentialsAuthentication("casey", "password")
        self.ingester_platform = IngesterPlatformAPI("http://localhost:8080", self.auth)
        self.cleanup_files = []
        
    def test_metadata_functionality(self):
        loc = Location(10.0, 11.0, "Test Site", 100, None)
        loc = self.ingester_platform.post(loc)
        
        dataset = Dataset(loc.id, {"file":"file"}, PullDataSource("http://www.bom.gov.au/radar/IDR733.gif", "file"))
        dataset1 = self.ingester_platform.post(dataset)
        self.assertEquals(dataset1.location, dataset.location, "Location ID does not match")
        self.assertEquals(dataset1.schema, dataset.schema, "schema does not match")

    def test_location_functionality(self):
        loc = Location(10.0, 11.0, "Test Site", 100, None)
        loc1 = self.ingester_platform.post(loc)
        self.assertNotEqual(loc1.id, None, "ID should have been set")
        self.assertEqual(loc.latitude, loc1.latitude, "latitude does not match")
        self.assertEqual(loc.longitude, loc1.longitude, "longitude does not match")
        self.assertEqual(loc.elevation, loc1.elevation, "elevation does not match")
        self.assertEqual(loc.name, loc1.name, "name does not match")

    def test_manual_ingest_functionality(self):
        pass

    def test_sampling_functionality(self):
        pass

    def test_processing_functionality(self):
        pass

    def tearDown(self):
        self.ingester_platform.reset()
        
class TestIngesterFunctionality(unittest.TestCase):
    """This set of tests test the actual functioning of the service.
    """
    def setUp(self):
        self.auth = CredentialsAuthentication("casey", "password")
        self.ingester_platform = IngesterPlatformAPI("http://localhost:8080", self.auth)
        self.cleanup_files = []
        
    def test_pull_ingest_functionality(self):
        loc = Location(10.0, 11.0, "Test Site", 100, None)
        loc = self.ingester_platform.post(loc)
        
        dataset = Dataset(loc.id, {"file":"file"}, PullDataSource("http://www.bom.gov.au/radar/IDR733.gif", "file"),
                PeriodicSampling(10000))
        dataset1 = self.ingester_platform.post(dataset)
        self.assertEquals(dataset1.location, dataset.location, "Location ID does not match")
        self.assertEquals(dataset1.schema, dataset.schema, "schema does not match")

    def tearDown(self):
        self.ingester_platform.reset()

#class TestProjectFunctionality(unittest.TestCase):
#    #---------------Create example data---------------
#    def setUp(self):
#        self.auth = CredentialsAuthentication("casey", "password")
#        self.ingester_platform = IngesterPlatformAPI("http://localhost:8080", self.auth)
#        self.cleanup_files = []
#
#    def test_connection(self):
#        result = self.ingester_platform.ping()
#        self.assertEquals(result, "PONG", "Could not ping service")
#
#    def test_ingest_functionality(self):
#        self.region = Region(
#            "Queensland",
#                [(2314, 1234), (1234, 1234), (1234, 1234), (1234, 2134)]
#        )
#
#        self.location = Location(1234, 1234, "Example Point", 1.5, self.region)
#
#        self.data_type = FileDataType()
#        self.data_type.extra_data_example = BOOLEAN()
#
#        self.script_handle = os.path.join(tempfile.gettempdir(), 'test_script_file.py')
#        self.cleanup_files.append(self.script_handle)
#        
#        script = "class TestProcessingScript(_ProcessingScript):"\
#                 "  def process_it(self, data_entry):"\
#                 "      assertIsInstance(data_entry, FileDataType)"\
#                 "      return {data_entry, DataEntry(data_entry.dataset, data_entry.data_type_schema, data_entry.datetime, {'processed':True})}"\
#                 ""
#        script_file = open(self.script_handle, 'w')
#        script_file.write(script)
#
#        self.dataset = Dataset(self.location, self.data_type, PushDataSource(sampling_script), self.script_handle)
#
#        self.data_entry = DataEntry(self.dataset, FileDataType(), 123456789,
#                {"mime_type": "text/xml", "file_handle": "c:/test.xml", "extra_data_example": False})
#
#        self.data_quality = Metadata(self.data_entry, QualityMetadataSchema(),
#                {"description": "The entered data was invalid."})
#        self.dataset_sampling_changed = Metadata(self.dataset, SampleRateMetadataSchema(),
#                {"change_time": datetime.today(), "sampling": PeriodicSampling(1000)})
#    # Datasets
#        try:
#            # Add a dataset
#            self.dataset = self.ingester_platform.post(self.dataset)
#
#            # Update the dataset with a ReDBox link after the metadata is entered.
#            self.dataset.redbox_link = "https://eresearch.jcu.edu.au/researchdata/123456789" # After entry into ReDBox
#            self.dataset = self.ingester_platform.post(self.dataset)
#
#            # Change the sampling rate of the dataset
#            self.dataset = self.ingester_platform.post(self.dataset_sampling_changed)
#
#            # Add a manual data entry
#            self.data_entry = self.ingester_platform.post(self.data_entry)
#
#            # Provide quality information on the data_entry
#            self.data_entry = self.ingester_platform.post(self.data_quality)
#
#            # Example of searching a range
#            start_search_id_range = DataEntry(data_entry_id=0)
#            start_search_id_range = DataEntry(data_entry_id=self.data_entry.data_entry_id)
#            found_data_entries = self.ingester_platform.get(start_search_id_range, start_search_id_range)
#            found = False
#            for data_entry in found_data_entries:
#                if data_entry == self.data_entry:
#                    # Delete the data_entry
#                    found = True
#            self.assertTrue(found, "id range search failed")
#
#            a_data_entry = DataEntry(kwargs={"extra_data_example": False})
#            data_entry = self.ingester_platform.get(DataEntry)
#            self.ingester_platform.delete(self.auth, self.data_entry)
#
#            # Get all datasets at the location
#            location_search = Dataset(self.location, None, None)
#            found_datasets = self.ingester_platform.get(location_search)
#            found = False
#            for dataset in found_datasets:
#                if dataset == self.dataset:
#                    # Delete the dataset
#                    self.ingester_platform.delete(self.auth, self.dataset)
#                    found = True
#            self.assertTrue(found, "location search failed")
#
#        except UnsupportedSchemaError:
#            assert True, "The data_type schema was an unknown type (this should never happen except under development"
#
#        except InvalidObjectError:
#            assert True, "Will occur if the model is invalid due to a not set required field or fields that are set "\
#                         "incorrectly (eg. data_schema is missing, location is an integer instead of a location object)"
#        except UnknownObjectError:
#            assert True, "Will occur if a non-ingester model object is posted. (eg. data_entry, dataset, location or metadata "\
#                         "are valid - sampling, data_sources or any other object are not)."
#        except AuthenticationError:
#            assert True, "The ingester API couldn't authenticate."
#        except ValueError:
#            assert True, "Any parameter that has an invalid value such as location.location_id isn't set"
#        except:
#            assert True, "Any other run time error that the ingester platform throws."
#
#    def tearDown(self):
#        self.ingester_platform.reset()
#        for f_name in self.cleanup_files:
#            if os.path.exists(f_name):
#                try:
#                    os.remove(f_name)
#                except:
#                    print "Exception: ", str(sys.exc_info())

if __name__ == '__main__':
    unittest.main()